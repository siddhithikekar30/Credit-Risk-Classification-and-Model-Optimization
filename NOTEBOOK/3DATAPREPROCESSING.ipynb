{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8a0734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /Users/mr.engineer/Desktop/Code/DSPROJECT/CREDITRISK/DATA/credit_risk_dataset.csv | shape: (32581, 12)\n",
      "After encoding shape: (32581, 27)\n",
      "Saved: /Users/mr.engineer/Desktop/Code/DSPROJECT/CREDITRISK/NOTEBOOK/artifacts_preprocessing/processed_all.csv\n",
      "Train/Val/Test saved in: /Users/mr.engineer/Desktop/Code/DSPROJECT/CREDITRISK/NOTEBOOK/artifacts_preprocessing\n",
      "Train: (19548, 27) | Val: (6516, 27) | Test: (6517, 27)\n",
      "\n",
      "✅ Preprocessing complete. Use:\n",
      "  - artifacts_preprocessing/processed_all.csv (full encoded data)\n",
      "  - artifacts_preprocessing/train.csv, val.csv, test.csv (for modeling)\n",
      "Next: Modeling notebook will read these CSVs directly.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Notebook 3: Data Preprocessing (encoding, no scaling)\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_PATH = \"/Users/mr.engineer/Desktop/Code/DSPROJECT/CREDITRISK/DATA/credit_risk_dataset.csv\"\n",
    "TARGET = \"loan_status\"   # 1 = default, 0 = repaid\n",
    "TEST_SIZE = 0.20\n",
    "VAL_SIZE  = 0.20          # part of remaining after test split\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "OUT_DIR = Path(\"artifacts_preprocessing\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- 1) Load ----------\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(\"Loaded:\", DATA_PATH, \"| shape:\", df.shape)\n",
    "assert TARGET in df.columns, f\"{TARGET} not found!\"\n",
    "\n",
    "# Keep original order (just in case)\n",
    "orig_cols = df.columns.tolist()\n",
    "\n",
    "# ---------- 2) Clean column names (good feature names) ----------\n",
    "def clean_name(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = s.replace(\"%\", \"pct\").replace(\"/\", \"_\").replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "    # keep only a-z, 0-9 and underscores\n",
    "    return \"\".join(ch if (ch.isalnum() or ch == \"_\") else \"_\" for ch in s)\n",
    "\n",
    "df.columns = [clean_name(c) for c in df.columns]\n",
    "if TARGET not in df.columns:\n",
    "    # handle if target got renamed by cleaning\n",
    "    # assume original target was loan_status -> clean is same\n",
    "    pass\n",
    "\n",
    "# ---------- 3) Basic target sanity ----------\n",
    "df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "# ---------- 4) Outlier handling (clip, but KEEP rows) ----------\n",
    "def iqr_clip(series: pd.Series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "# Obvious impossible caps if present\n",
    "if \"person_age\" in df.columns:\n",
    "    df.loc[df[\"person_age\"] > 100, \"person_age\"] = 100\n",
    "if \"person_emp_length\" in df.columns:\n",
    "    df.loc[df[\"person_emp_length\"] > 80, \"person_emp_length\"] = 80\n",
    "\n",
    "# Clip tails for a couple of skewed numerics (adjust list as needed)\n",
    "for col in [\"person_income\", \"loan_amnt\"]:\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[col] = iqr_clip(df[col])\n",
    "\n",
    "# ---------- 5) Impute missing values ----------\n",
    "# numeric -> median; categorical -> most frequent\n",
    "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c != TARGET]\n",
    "cat_cols = [c for c in df.columns if c not in num_cols + [TARGET]]\n",
    "\n",
    "# Fill numeric NaNs\n",
    "for c in num_cols:\n",
    "    med = df[c].median()\n",
    "    df[c] = df[c].fillna(med)\n",
    "\n",
    "# Fill categorical NaNs\n",
    "for c in cat_cols:\n",
    "    mode_val = df[c].mode(dropna=True)\n",
    "    mode_val = mode_val.iloc[0] if not mode_val.empty else \"missing\"\n",
    "    df[c] = df[c].fillna(mode_val).astype(str)\n",
    "\n",
    "# ---------- 6) One-Hot Encode categoricals (no drop_first) ----------\n",
    "# We keep all dummies for interpretability; tree models don’t need scaling.\n",
    "if len(cat_cols) > 0:\n",
    "    df_encoded = pd.get_dummies(df, columns=cat_cols, prefix=cat_cols, drop_first=False)\n",
    "else:\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "# Ensure target is the last column (optional, nice for reading)\n",
    "cols = [c for c in df_encoded.columns if c != TARGET] + [TARGET]\n",
    "df_encoded = df_encoded[cols]\n",
    "\n",
    "print(\"After encoding shape:\", df_encoded.shape)\n",
    "\n",
    "# Save full processed dataset\n",
    "processed_all_path = OUT_DIR / \"processed_all.csv\"\n",
    "df_encoded.to_csv(processed_all_path, index=False)\n",
    "print(\"Saved:\", processed_all_path.resolve())\n",
    "\n",
    "# Save feature list (exclude target)\n",
    "feature_cols = [c for c in df_encoded.columns if c != TARGET]\n",
    "with open(OUT_DIR / \"feature_list.txt\", \"w\") as f:\n",
    "    for c in feature_cols:\n",
    "        f.write(c + \"\\n\")\n",
    "\n",
    "# ---------- 7) Stratified Train/Val/Test splits (on encoded data) ----------\n",
    "X = df_encoded.drop(columns=[TARGET])\n",
    "y = df_encoded[TARGET]\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "val_ratio_of_trainval = VAL_SIZE / (1 - TEST_SIZE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=val_ratio_of_trainval,\n",
    "    stratify=y_train_val,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Recombine to single CSVs with same columns\n",
    "train_df = X_train.copy(); train_df[TARGET] = y_train.values\n",
    "val_df   = X_val.copy();   val_df[TARGET]   = y_val.values\n",
    "test_df  = X_test.copy();  test_df[TARGET]  = y_test.values\n",
    "\n",
    "train_df.to_csv(OUT_DIR / \"train.csv\", index=False)\n",
    "val_df.to_csv(OUT_DIR / \"val.csv\", index=False)\n",
    "test_df.to_csv(OUT_DIR / \"test.csv\", index=False)\n",
    "\n",
    "print(\"Train/Val/Test saved in:\", OUT_DIR.resolve())\n",
    "print(\"Train:\", train_df.shape, \"| Val:\", val_df.shape, \"| Test:\", test_df.shape)\n",
    "\n",
    "# ---------- 8) Quick report ----------\n",
    "report_lines = []\n",
    "report_lines.append(\"Preprocessing report\")\n",
    "report_lines.append(f\"Original shape: {tuple(pd.read_csv(DATA_PATH, nrows=1).shape)} (rows unknown here)\")\n",
    "report_lines.append(f\"Processed (encoded) shape: {df_encoded.shape}\")\n",
    "report_lines.append(f\"Numeric cols (pre-encode): {len(num_cols)} | Categorical cols: {len(cat_cols)}\")\n",
    "report_lines.append(\"Outlier handling: capped person_age > 100, person_emp_length > 80; IQR clip on person_income & loan_amnt\")\n",
    "report_lines.append(\"Missing values: numeric->median, categorical->mode\")\n",
    "report_lines.append(\"Encoding: One-Hot (no drop_first)\")\n",
    "report_lines.append(f\"Files: {processed_all_path.name}, train.csv, val.csv, test.csv, feature_list.txt\")\n",
    "\n",
    "with open(OUT_DIR / \"report.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(report_lines))\n",
    "\n",
    "print(\"\\n✅ Preprocessing complete. Use:\")\n",
    "print(\"  - artifacts_preprocessing/processed_all.csv (full encoded data)\")\n",
    "print(\"  - artifacts_preprocessing/train.csv, val.csv, test.csv (for modeling)\")\n",
    "print(\"Next: Modeling notebook will read these CSVs directly.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
